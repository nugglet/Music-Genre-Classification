{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(1)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Data/features_30_sec.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_modified = df.drop(df[df.filename == \"jazz.00054.wav\"].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "infile = open(\"mfcc_list\",'rb')\n",
    "mfcc_list = pickle.load(infile)\n",
    "infile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df_modified['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc_sizes = []\n",
    "\n",
    "for i in mfcc_list:\n",
    "    mfcc_sizes.append(i.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(mfcc_list)):\n",
    "    if mfcc_list[i].shape[1] >= min(mfcc_sizes):\n",
    "        mfcc_list[i] = np.resize(mfcc_list[i], (32, min(mfcc_sizes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    mfcc_list, labels, test_size=0.2, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "le = LabelBinarizer()\n",
    "y_train = le.fit_transform(y_train.values)\n",
    "y_test = le.transform(y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def force_cudnn_initialization():\n",
    "    s = 32\n",
    "    dev = torch.device('cuda')\n",
    "    torch.nn.functional.conv2d(torch.zeros(s, s, s, s, device=dev), torch.zeros(s, s, s, s, device=dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_acc(y_pred, y_test):\n",
    "    y_pred_softmax = F.softmax(y_pred, dim = 1)\n",
    "    _, y_pred_tags = torch.max(y_pred_softmax, dim = 1)\n",
    "    _, y_test_tags = torch.max(y_test, dim = 1) \n",
    "    \n",
    "    correct_pred = (y_pred_tags == y_test_tags).float()\n",
    "    acc = correct_pred.sum() / len(correct_pred)\n",
    "    \n",
    "    acc = torch.round(acc * 100)\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "force_cudnn_initialization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUNet(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_size, batch_size):\n",
    "        super(GRUNet, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.batch = batch_size\n",
    "        self.input_dim = input_dim\n",
    "        drp = 0.1\n",
    "        n_classes = len(le.classes_)\n",
    "        self.gru = nn.GRU(self.input_dim, self.hidden_size)\n",
    "        self.fc1 = nn.Linear(self.hidden_size, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(drp)\n",
    "        self.out = nn.Linear(64, n_classes)\n",
    "        # self.softmax = nn.Softmax(n_classes)\n",
    "    \n",
    "    def initialize_hidden_state(self, device):\n",
    "        return torch.zeros((1, self.batch, self.hidden_size)).to(device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.hidden = self.initialize_hidden_state(device)\n",
    "        gru, self.hidden = self.gru(x, self.hidden)\n",
    "        out = self.dropout(gru[-1, :, :])\n",
    "        fc1 = self.dropout(self.relu(self.fc1(out)))\n",
    "        fc2 = self.dropout(self.relu(self.fc2(fc1)))\n",
    "        out = self.out(fc2)\n",
    "        return out, self.hidden\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRUNet(\n",
      "  (gru): GRU(20, 256)\n",
      "  (fc1): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (out): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torchvision import models\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dksat\\AppData\\Local\\Temp\\ipykernel_8112\\1518406094.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_train = torch.tensor(y_train, dtype=torch.float).cuda()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 \t loss=73.8278 \t acc=9.17% \t val_loss=73.7470 \t val_acc=9.33% \t time=0.16s\n",
      "Epoch 2/20 \t loss=73.7728 \t acc=9.58% \t val_loss=73.6836 \t val_acc=9.83% \t time=0.16s\n",
      "Epoch 3/20 \t loss=73.8509 \t acc=9.54% \t val_loss=73.7807 \t val_acc=8.33% \t time=0.16s\n",
      "Epoch 4/20 \t loss=73.7471 \t acc=12.54% \t val_loss=73.8128 \t val_acc=8.17% \t time=0.15s\n",
      "Epoch 5/20 \t loss=73.9276 \t acc=10.08% \t val_loss=73.8559 \t val_acc=9.33% \t time=0.16s\n",
      "Epoch 6/20 \t loss=73.7820 \t acc=9.00% \t val_loss=73.8917 \t val_acc=10.33% \t time=0.16s\n",
      "Epoch 7/20 \t loss=73.8182 \t acc=10.33% \t val_loss=73.9496 \t val_acc=8.67% \t time=0.16s\n",
      "Epoch 8/20 \t loss=73.7310 \t acc=11.25% \t val_loss=73.8610 \t val_acc=7.67% \t time=0.15s\n",
      "Epoch 9/20 \t loss=73.7561 \t acc=8.88% \t val_loss=73.8978 \t val_acc=6.00% \t time=0.16s\n",
      "Epoch 10/20 \t loss=73.7733 \t acc=9.12% \t val_loss=73.8634 \t val_acc=8.00% \t time=0.16s\n",
      "Epoch 11/20 \t loss=73.6813 \t acc=11.17% \t val_loss=73.8527 \t val_acc=7.83% \t time=0.16s\n",
      "Epoch 12/20 \t loss=73.7320 \t acc=10.00% \t val_loss=73.8317 \t val_acc=9.00% \t time=0.16s\n",
      "Epoch 13/20 \t loss=73.7270 \t acc=10.50% \t val_loss=73.9172 \t val_acc=8.17% \t time=0.16s\n",
      "Epoch 14/20 \t loss=73.7452 \t acc=10.29% \t val_loss=73.9439 \t val_acc=5.50% \t time=0.16s\n",
      "Epoch 15/20 \t loss=73.6900 \t acc=11.88% \t val_loss=73.8835 \t val_acc=5.50% \t time=0.17s\n",
      "Epoch 16/20 \t loss=73.7800 \t acc=9.75% \t val_loss=73.9526 \t val_acc=7.50% \t time=0.16s\n",
      "Epoch 17/20 \t loss=73.5988 \t acc=10.12% \t val_loss=74.0536 \t val_acc=5.50% \t time=0.16s\n",
      "Epoch 18/20 \t loss=73.5326 \t acc=11.75% \t val_loss=74.0476 \t val_acc=7.00% \t time=0.16s\n",
      "Epoch 19/20 \t loss=73.6766 \t acc=9.17% \t val_loss=74.0600 \t val_acc=4.50% \t time=0.16s\n",
      "Epoch 20/20 \t loss=73.7678 \t acc=10.88% \t val_loss=74.0346 \t val_acc=5.50% \t time=0.16s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "n_epochs = 20\n",
    "batch_size = 32\n",
    "model = GRUNet(1290, 256, batch_size)\n",
    "loss_fn = nn.CrossEntropyLoss(reduction=\"sum\")\n",
    "optimizer = torch.optim.Adam(\n",
    "    filter(lambda p: p.requires_grad, model.parameters()), lr=0.0001\n",
    ")\n",
    "\n",
    "model.cuda()\n",
    "\n",
    "# Load train and test in CUDA Memory\n",
    "x_train = torch.tensor(X_train, dtype=torch.float).cuda()\n",
    "y_train = torch.tensor(y_train, dtype=torch.float).cuda()\n",
    "x_cv = torch.tensor(X_test, dtype=torch.float).cuda()\n",
    "y_cv = torch.tensor(y_test, dtype=torch.float).cuda()\n",
    "\n",
    "# Create Torch datasets\n",
    "train = torch.utils.data.TensorDataset(x_train, y_train)\n",
    "valid = torch.utils.data.TensorDataset(x_cv, y_cv)\n",
    "\n",
    "# Create Data Loaders\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "valid_loader = torch.utils.data.DataLoader(valid, batch_size=batch_size, shuffle=False, drop_last = True)\n",
    "\n",
    "train_loss = []\n",
    "valid_loss = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    start_time = time.time()\n",
    "    # Set model to train configuration\n",
    "    model.train()\n",
    "    avg_loss = 0.0\n",
    "    accuracy = []\n",
    "    for i, (x_batch, y_batch) in enumerate(train_loader):\n",
    "        # Predict/Forward Pass\n",
    "        y_pred, hidden = model(x_batch)\n",
    "        # # Casting\n",
    "        # x_batch = x_batch.to(device)\n",
    "        # y_batch = y_batch.type(torch.LongTensor)\n",
    "        # y_batch = y_batch.to(device)\n",
    "        # Compute loss\n",
    "        # print(y_pred)\n",
    "        #print(x_batch.shape, y_batch.shape)\n",
    "        loss = loss_fn(y_pred, y_batch)\n",
    "        acc = multi_acc(y_pred, y_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        avg_loss += loss.item() / len(train_loader)\n",
    "        accuracy.append(acc.item())\n",
    "\n",
    "    # Set model to validation configuration -Doesn't get trained here\n",
    "    model.eval()\n",
    "    avg_val_loss = 0.0\n",
    "    val_accuracy = []\n",
    "    val_preds = np.zeros((len(x_cv), len(le.classes_)))\n",
    "\n",
    "    for i, (x_batch, y_batch) in enumerate(valid_loader):\n",
    "        # Casting\n",
    "        # x_batch = x_batch.to(device)\n",
    "        # y_batch = y_batch.type(torch.LongTensor)\n",
    "        # y_batch = y_batch.to(device)\n",
    "        # Detach\n",
    "        y_pred, hidden2 = model(x_batch)\n",
    "        y_pred = y_pred.detach()\n",
    "        val_acc = multi_acc(y_pred, y_batch)\n",
    "        avg_val_loss += loss_fn(y_pred, y_batch).item() / len(valid_loader)\n",
    "        val_accuracy.append(val_acc.item())\n",
    "\n",
    "    # Check Accuracy\n",
    "    # val_accuracy = sum(val_preds.argmax(axis=1) == y_test) / len(y_test)\n",
    "    train_loss.append(avg_loss)\n",
    "    valid_loss.append(avg_val_loss)\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(\n",
    "        \"Epoch {}/{} \\t loss={:.4f} \\t acc={:.2f}% \\t val_loss={:.4f} \\t val_acc={:.2f}% \\t time={:.2f}s\".format(\n",
    "            epoch + 1, n_epochs, avg_loss, np.mean(accuracy), avg_val_loss, np.mean(val_accuracy), elapsed_time\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0ca786e00441f7520b00a844524182a7ff21fa60a408ec698ee2babb434ff995"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
