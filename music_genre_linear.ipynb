{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(1)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Data/features_30_sec.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_modified = df.drop(df[df.filename == \"jazz.00054.wav\"].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "infile = open(\"mfcc_list\",'rb')\n",
    "mfcc_list = pickle.load(infile)\n",
    "infile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df_modified['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc_sizes = []\n",
    "\n",
    "for i in mfcc_list:\n",
    "    mfcc_sizes.append(i.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(mfcc_list)):\n",
    "    if mfcc_list[i].shape[1] >= min(mfcc_sizes):\n",
    "        mfcc_list[i] = np.resize(mfcc_list[i], (20, min(mfcc_sizes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    mfcc_list, labels, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "le = LabelBinarizer()\n",
    "y_train = le.fit_transform(y_train.values)\n",
    "y_test = le.transform(y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def force_cudnn_initialization():\n",
    "    s = 32\n",
    "    dev = torch.device('cuda')\n",
    "    torch.nn.functional.conv2d(torch.zeros(s, s, s, s, device=dev), torch.zeros(s, s, s, s, device=dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "force_cudnn_initialization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Linear, self).__init__()\n",
    "        self.hidden_size = 1290\n",
    "        drp = 0.1\n",
    "        n_classes = len(le.classes_)\n",
    "        self.fc1 = nn.Linear(1290*20, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 256)\n",
    "        self.fc4 = nn.Linear(256, 128)\n",
    "        self.fc5 = nn.Linear(128, 64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(drp)\n",
    "        self.out = nn.Linear(64, n_classes)\n",
    "        # self.softmax = nn.Softmax(n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        fc1 = self.dropout(self.relu(self.fc1(x)))\n",
    "        fc2 = self.dropout(self.relu(self.fc2(fc1)))\n",
    "        fc3 = self.dropout(self.relu(self.fc3(fc2)))\n",
    "        fc4 = self.dropout(self.relu(self.fc4(fc3)))\n",
    "        fc5 = self.dropout(self.relu(self.fc5(fc4)))\n",
    "        out = self.out(fc5)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_acc(y_pred, y_test):\n",
    "    y_pred_softmax = F.softmax(y_pred, dim = 1)\n",
    "    _, y_pred_tags = torch.max(y_pred_softmax, dim = 1)\n",
    "    _, y_test_tags = torch.max(y_test, dim = 1) \n",
    "    \n",
    "    correct_pred = (y_pred_tags == y_test_tags).float()\n",
    "    acc = correct_pred.sum() / len(correct_pred)\n",
    "    \n",
    "    acc = torch.round(acc * 100)\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_145820/1893571012.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_train = torch.tensor(y_train, dtype=torch.float).cuda()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 \t loss=70.5245 \t acc=22.80% \t val_loss=56.9808 \t val_acc=23.71% \t time=0.19s\n",
      "Epoch 2/20 \t loss=60.7244 \t acc=31.08% \t val_loss=50.7228 \t val_acc=30.43% \t time=0.19s\n",
      "Epoch 3/20 \t loss=55.3707 \t acc=36.52% \t val_loss=48.7639 \t val_acc=34.29% \t time=0.18s\n",
      "Epoch 4/20 \t loss=52.0229 \t acc=39.28% \t val_loss=50.0579 \t val_acc=34.86% \t time=0.18s\n",
      "Epoch 5/20 \t loss=49.3969 \t acc=44.20% \t val_loss=48.7090 \t val_acc=40.29% \t time=0.18s\n",
      "Epoch 6/20 \t loss=44.6894 \t acc=50.88% \t val_loss=44.0610 \t val_acc=47.00% \t time=0.18s\n",
      "Epoch 7/20 \t loss=42.9247 \t acc=52.36% \t val_loss=41.5812 \t val_acc=45.57% \t time=0.18s\n",
      "Epoch 8/20 \t loss=38.9651 \t acc=58.56% \t val_loss=45.0380 \t val_acc=45.14% \t time=0.18s\n",
      "Epoch 9/20 \t loss=34.1048 \t acc=62.64% \t val_loss=44.0487 \t val_acc=50.43% \t time=0.18s\n",
      "Epoch 10/20 \t loss=32.8102 \t acc=61.68% \t val_loss=42.9076 \t val_acc=47.86% \t time=0.19s\n",
      "Epoch 11/20 \t loss=29.7969 \t acc=67.28% \t val_loss=45.1633 \t val_acc=50.29% \t time=0.19s\n",
      "Epoch 12/20 \t loss=26.0154 \t acc=71.60% \t val_loss=47.3301 \t val_acc=46.57% \t time=0.18s\n",
      "Epoch 13/20 \t loss=22.8625 \t acc=75.28% \t val_loss=43.4725 \t val_acc=51.57% \t time=0.18s\n",
      "Epoch 14/20 \t loss=19.8357 \t acc=78.92% \t val_loss=47.9877 \t val_acc=50.86% \t time=0.19s\n",
      "Epoch 15/20 \t loss=17.1996 \t acc=81.60% \t val_loss=43.3810 \t val_acc=51.43% \t time=0.19s\n",
      "Epoch 16/20 \t loss=14.0513 \t acc=86.72% \t val_loss=49.8733 \t val_acc=52.29% \t time=0.18s\n",
      "Epoch 17/20 \t loss=12.3036 \t acc=86.84% \t val_loss=48.1996 \t val_acc=55.57% \t time=0.19s\n",
      "Epoch 18/20 \t loss=11.3575 \t acc=88.60% \t val_loss=53.4558 \t val_acc=52.29% \t time=0.18s\n",
      "Epoch 19/20 \t loss=8.4624 \t acc=92.60% \t val_loss=51.5937 \t val_acc=55.71% \t time=0.18s\n",
      "Epoch 20/20 \t loss=8.9166 \t acc=91.68% \t val_loss=49.7976 \t val_acc=58.29% \t time=0.19s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "n_epochs = 20\n",
    "batch_size = 32\n",
    "model = Linear()\n",
    "loss_fn = nn.CrossEntropyLoss(reduction=\"sum\")\n",
    "optimizer = torch.optim.Adam(\n",
    "    filter(lambda p: p.requires_grad, model.parameters()), lr=0.0001\n",
    ")\n",
    "\n",
    "model.cuda()\n",
    "\n",
    "# Load train and test in CUDA Memory\n",
    "x_train = torch.tensor(X_train, dtype=torch.float).cuda()\n",
    "y_train = torch.tensor(y_train, dtype=torch.float).cuda()\n",
    "x_cv = torch.tensor(X_test, dtype=torch.float).cuda()\n",
    "y_cv = torch.tensor(y_test, dtype=torch.float).cuda()\n",
    "\n",
    "# Create Torch datasets\n",
    "train = torch.utils.data.TensorDataset(x_train, y_train)\n",
    "valid = torch.utils.data.TensorDataset(x_cv, y_cv)\n",
    "\n",
    "# Create Data Loaders\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(valid, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "train_loss = []\n",
    "valid_loss = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    start_time = time.time()\n",
    "    # Set model to train configuration\n",
    "    model.train()\n",
    "    avg_loss = 0.0\n",
    "    accuracy = []\n",
    "    for i, (x_batch, y_batch) in enumerate(train_loader):\n",
    "        # Predict/Forward Pass\n",
    "        y_pred = model(x_batch)\n",
    "        # # Casting\n",
    "        # x_batch = x_batch.to(device)\n",
    "        # y_batch = y_batch.type(torch.LongTensor)\n",
    "        # y_batch = y_batch.to(device)\n",
    "        # Compute loss\n",
    "        # print(y_pred)\n",
    "        loss = loss_fn(y_pred, y_batch)\n",
    "        acc = multi_acc(y_pred, y_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        avg_loss += loss.item() / len(train_loader)\n",
    "        accuracy.append(acc.item())\n",
    "\n",
    "    # Set model to validation configuration -Doesn't get trained here\n",
    "    model.eval()\n",
    "    avg_val_loss = 0.0\n",
    "    val_accuracy = []\n",
    "    val_preds = np.zeros((len(x_cv), len(le.classes_)))\n",
    "\n",
    "    for i, (x_batch, y_batch) in enumerate(valid_loader):\n",
    "        # Casting\n",
    "        # x_batch = x_batch.to(device)\n",
    "        # y_batch = y_batch.type(torch.LongTensor)\n",
    "        # y_batch = y_batch.to(device)\n",
    "        # Detach\n",
    "        y_pred = model(x_batch).detach()\n",
    "        val_acc = multi_acc(y_pred, y_batch)\n",
    "        avg_val_loss += loss_fn(y_pred, y_batch).item() / len(valid_loader)\n",
    "        val_accuracy.append(val_acc.item())\n",
    "\n",
    "    # Check Accuracy\n",
    "    # val_accuracy = sum(val_preds.argmax(axis=1) == y_test) / len(y_test)\n",
    "    train_loss.append(avg_loss)\n",
    "    valid_loss.append(avg_val_loss)\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(\n",
    "        \"Epoch {}/{} \\t loss={:.4f} \\t acc={:.2f}% \\t val_loss={:.4f} \\t val_acc={:.2f}% \\t time={:.2f}s\".format(\n",
    "            epoch + 1, n_epochs, avg_loss, np.mean(accuracy), avg_val_loss, np.mean(val_accuracy), elapsed_time\n",
    "        )\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0ca786e00441f7520b00a844524182a7ff21fa60a408ec698ee2babb434ff995"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('DLProject')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
